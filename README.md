# Wikipedia Source Analysis
## About
This project analyses [Wikipedia Database Dumps][1] and attempts to determine on
average the quality of Wikipedia articles overall.

I used [Python][2] **3.5.1** on Windows 64-bit. The [xml.sax][3] and [lxml][4] modules were used for processing the database dump from Wikipedia.

Of course there is significant overhead associated with the large file size and
amount of data generated by this program.


## Files in this repo
  * ``articles-sax.py``
    * Ran in PowerShell ``Measure-Command {python.exe .\articles-sax.py | Out-Default}``
    * Uses [xml.sax][3]
    * Gets the titles of all articles in the database dump file and prints them to ``out.txt``
    * Total number of articles is printed to ``STDOUT``
    * Never completed on my machine
  * ``articles-lxml.py``
    * Ran in PowerShell ``Measure-Command {python.exe ./articles-lxml.py | Out-Default}``
    * Uses [lxml][4]
    * Ran in __number of seconds__ on my machine

[1]: https://en.wikipedia.org/wiki/Wikipedia:Database_download#Where_do_I_get...
[2]: https://www.python.org/
[3]: https://docs.python.org/3/library/xml.sax.html
[4]: http://lxml.de/
