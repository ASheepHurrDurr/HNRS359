# Wikipedia Source Analysis
## About
This project analyses [Wikipedia Database Dumps][1] and attempts to determine on
average the quality of Wikipedia articles overall.

I used [Python][2] **3.5.1** on Windows 64-bit. The [xml.sax][3] module was used for
processing the database dump from Wikipedia.

Of course there is significant overhead associated with the large file size and
amount of data generated by this program.

[1]: https://en.wikipedia.org/wiki/Wikipedia:Database_download#Where_do_I_get...
[2]: https://www.python.org/
[3]: https://docs.python.org/3/library/xml.sax.html

## Files in this repo
  * ``articles.py``
    * Ran in PowerShell ``Measure-Command {python.exe .\test.py | Out-Default}``
    * Gets the titles of all articles in the database dump file and prints them to ``out.txt``
    * Total number of articles is printed to ``STDOUT``
    * Running this took __number of seconds__ on my machine
